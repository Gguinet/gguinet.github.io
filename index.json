[{"authors":null,"categories":null,"content":"I am a second-year master student at the MIT Operations Research Center, advised by Prof. Saurabh Amin and Prof. Patrick Jaillet. My research at MIT focuses on theoretical and algorithmic contributions to the field of Decision Making under Uncertainty, with applications in transportation, pricing and recommender systems. More broadly, I seek to explore how mathematical and computational techniques can help us understand, predict and ultimately improve human behavior in challenging situations.\nPrior to joining MIT, I graduated from Ecole Polytechnique majoring in Applied Mathematics and completed two years of preparatory program (CPGE) in Lycée Sainte Geneviève.\nDuring my undergrad studies, I did some research in Machine Learning (Bayesian Optimization for AutoML, Learning to rank for journalistic fact-checking and Unsupervised Bilingual Induction), Finance (information aggregation for portfolio construction) and Healthcare (neuronal coordination dynamics and causal inference to measure treatment effect). In the context of those projects, I had the pleasure to work among other with Prof. Augustin Landier, Prof. Ioana Manolescu and Prof. Laurent Massoulié. I also have had the opportunity to intern at several tech companies or research labs including Amazon Web Services (Berlin Team), INRIA (Paris) and Chorus.\n","date":1651363200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1651363200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a second-year master student at the MIT Operations Research Center, advised by Prof. Saurabh Amin and Prof. Patrick Jaillet. My research at MIT focuses on theoretical and algorithmic contributions to the field of Decision Making under Uncertainty, with applications in transportation, pricing and recommender systems.","tags":null,"title":"Gauthier Guinet","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://gguinet.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Gauthier Guinet","Saurabh Amin","Patrick Jaillet"],"categories":null,"content":"","date":1651363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651363200,"objectID":"b43c1cbd250eb3aa436fd5b361699c75","permalink":"https://gguinet.github.io/publication/censoredbandits/","publishdate":"2022-05-01T00:00:00Z","relpermalink":"/publication/censoredbandits/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Effective Dimension in Bandit Problems under Censorship","type":"publication"},{"authors":null,"categories":null,"content":"In Haghtalab et al., 2019, polarization of belief is studied through the lens of statistical learning theory. Aside from the innovative ideas, the main theoretical contribution is the introduction of diameter inequalities on an hypothesis class, leveraging only the structure induced by the pseudo metric related to the 0-1 loss. Such diameter is mapped to the maximal disagreement between agents and thus the potential polarization. More precisely, they establish some PAC style bounds on the maximal distance between two penalized ERM hypothesis and study the impact of small modification of the distribution on this distance. With this in mind, this work leverages their framework to further study diameter inequalities under the existence of penalization, without making any assumptions on the structure of the hypothesis space nor on the form of such penalization. Particular attention is given to asymptotic diameter and convergence of empirical and expected approximation sets, called Rashomon Sets. Roughly speaking, we wonder to what extent polarization is robust w.r.t. the penalization? In others words, we analyse the impact of modifications of the penalization associated with hypothesis (i.e.education) on polarization. The second part of the work lays the groundwork of an algorithm whose goal is to introduce bias in the initial distribution in order to reduce maximal diameter, studying an open question of Haghtalab et al., 2019. In particular, some links are established with a line of work in Active Learning community tackling related questions.\n","date":1607731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607731200,"objectID":"7bd1f48f9a7f721108c580cde7cc7886","permalink":"https://gguinet.github.io/project/polabelief2020/","publishdate":"2020-12-12T00:00:00Z","relpermalink":"/project/polabelief2020/","section":"project","summary":"In [Haghtalab et al., 2019](https://www.microsoft.com/en-us/research/publication/polarization-through-the-lens-of-learning-theory/), polarization of belief is studied through the lens of statistical learning theory. Aside from the innovative ideas, the main theoretical contribution is the introduction of diameter inequalities on an hypothesis class, leveraging only the structure induced by the pseudo metric related to the 0-1 loss. Such diameter is mapped to the maximal disagreement between agents and thus the potential polarization. More precisely, they establish some PAC style bounds on the maximal distance between two penalized ERM hypothesis and study the impact of small modification of the distribution on this distance. With this in mind, this work leverages their framework to further study diameter inequalities under the existence of penalization, without making any assumptions on the structure of the hypothesis space nor on the form of such penalization. Particular attention is given to asymptotic diameter and convergence of empirical and expected approximation sets, called Rashomon Sets. Roughly speaking, we wonder to what extent polarization is robust w.r.t. the penalization? In others words, we analyse the impact of modifications of the penalization associated with hypothesis (i.e.education) on polarization. The second part of the work lays the groundwork of an algorithm whose goal is to introduce bias in the initial distribution in order to reduce maximal diameter, studying an open question of [Haghtalab et al., 2019](https://www.microsoft.com/en-us/research/publication/polarization-through-the-lens-of-learning-theory/). In particular, some links are established with a line of work in Active Learning community tackling related questions.","tags":null,"title":"From polarization of belief to Active learning theory: a diameter approach","type":"project"},{"authors":["Gauthier Guinet","Valerio Perrone","Cédric Archambeau"],"categories":null,"content":"","date":1606089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606089600,"objectID":"984859a745080cab52698edfbd649a2f","permalink":"https://gguinet.github.io/publication/cost_awarebo/","publishdate":"2020-11-23T00:00:00Z","relpermalink":"/publication/cost_awarebo/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Pareto-efficient Acquisition Functions for Cost-Aware Bayesian Optimization","type":"publication"},{"authors":["Gauthier Guinet","Paul Garnier"],"categories":null,"content":"This blog post contains an introduction to Unsupervised Bilingual Alignment and Multilingual Alignment. We also go through the theoretical framework behind Learning to Rank and discuss how it might help produce better alignments in a Semi-Supervised fashion. This post was written with Paul Garnier and was initially supposed to explore the impact of learning to rank to Unsupervised Translation. We both hope that this post will serve as a good introduction to anyone interested in this topic.\ncode.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}  MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\\\(','\\\\)']], skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry } }); MathJax.Hub.Queue(function() { var all = MathJax.Hub.getAllJax(), i; for(i = 0; i  Introduction   Example of the embedding of \"Etudiant\" in 6 dimensions.    Word vectors are conceived to synthesize and quantify semantic nuances, using a few hundred coordinates. These are generally used in downstream tasks to improve generalization when the amount of data is scarce. The widespread use and successes of these \"word embeddings\" in monolingual tasks have inspired further research on the induction of multilingual word embeddings for two or more languages in the same vector space.   Words embeddings in 2 different languages but in the same vector space.    The starting point was the discovery [[4]](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) that word embedding spaces have similar structures across languages, even when considering distant language pairs like English and Vietnamese. More precisely, two sets of pre-trained vectors in different languages can be aligned to some extent: good word translations can be produced through a simple linear mapping between the two sets of embeddings. For example, learning a direct mapping between Italian and Portuguese leads to a word translation accuracy of 78.1% with a nearest neighbor (NN) criterion.   Example of a direct mapping and translation with a NN criterion for French and English.    Embeddings of translations and words with similar meaning are close (geometrically) in the shared cross-lingual vector space. This property makes them very effective for cross-lingual Natural Language Processing (NLP) tasks. The simplest way to evaluate the result is the Bilingual Lexicon Induction (BLI) criterion, which designs the dictionary's percentage that can be correctly induced. Thus, BLI is often the first step towards several downstream tasks such as Part-Of-Speech (POS) tagging, parsing, document classification, language genealogy analysis, or (unsupervised) machine translation. These common representations are frequently learned through a two-step process, whether in a bilingual or multilingual setting. First, monolingual word representations are learned over large portions of text; these pre-formed representations are actually available for several languages and are widely used, such as the Fasttext Wikipedia. Second, a correspondence between languages is learned in three ways: in a supervised manner, if parallel dictionaries or data are available to be used for supervisory purposes, with minimal supervision, for example, by using only identical strings, or in a completely unsupervised manner.\nIt is common practice in the literature on the subject to separate these two steps and not to address them simultaneously in a paper. Indeed, measuring the algorithm\u0026rsquo;s efficiency would lose its meaning if the corpus of vectors is not identical at the beginning.\nConcerning the second point, although three different approaches exist, they are broadly based on the same ideas: the goal is to identify a subset of points that are then used as anchors points to achieve alignment. In the supervised approach, these are the words for which the translation is available. In the semi-supervised approach, we will gradually try to enrich the small initial corpus to have more and more anchor points. The non-supervised approach differs because there is no parallel corpus or dictionary between the two languages. The subtlety of the algorithms will be to release a potential dictionary and then to enrich it progressively.\nWe will focus on this third approach. Although it is a less frequent scenario, it is of great interest for several reasons. First of all, from a theoretical point of view, it provides a practical answer to a fascinating problem of information theory: given a set of texts in a totally unknown language, what information can we retrieve? The algorithms we chose to implement contrast neatly with the classical approach used until now. Finally, for very distinct languages or languages that are no longer used, the common corpus can indeed be very thin.\nMany developments have therefore taken place in recent years in this field of unsupervised bilingual lexicon induction. One of the recent discoveries is the idea that using information from other languages during the training process helps improve translating language pairs.\nThis discovery led us to formulate the problem as follows: is it possible to gain experience in the progressive learning of several languages? In other words, how can we make fair use of the learning of several acquired languages to learn a new one? This new formulation can lead one to consider the lexicon induction as a ranking problem.\nWe will proceed as follows: First, we will outline state of the art and the different techniques used for unsupervised learning in this context. In particular, we will explain the Wasserstein Procrustes approach for bilingual and multi alignment. We then emphasize the lexicon induction given the alignment. We then present the Learning to Rank key concepts. We then discuss a method using learning to rank for lexicon induction, and then present some experimental results.\nUnsupervised Bilingual Alignment This section provides a brief overview of unsupervised bilingual alignment methods to learn a mapping between two sets of embeddings. The majority are divided into two stages: the actual alignment and lexicon induction, given the alignment. Even if the lexicon induction is often taken into account when aligning (directly or indirectly, through the loss function), this distinction is useful from a theoretical perspective.\n  Word embeddings alignment (in dimension 2).    Historically, the problem of word vector alignment has been formulated as as a quadratic problem. This approach, resulting from the supervised literature, is then allowed to presume the absence of lexicon without modifying the framework. That is why we will deal with it first in what follows. Orthogonal Procrustes Problem   Set of n words (embeddings of dimensions d) for 2 languages.    Procustes is a method that aligns points if given the correspondences between them (supervised scenario). $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ and $\\mathbf{Y} \\in \\mathbb{R}^{n \\times d}$ are the two sets of word embeddings or points and we suppose, as previously said, that we know which point **X** corresponds to which point **Y**. This leads us to solve the following least-square problem of optimization, looking for the **W** matrix performing the alignment [[5]](https://arxiv.org/pdf/1805.11222.pdf):   Operation applied for each word in the first language. The goal is to minimize the distance between the orange and the blue vectors.    We have access to a closed form solution with a cubic complexity. Restraining **W** to the set of orthogonal matrices $\\mathcal{O}_{d}$, improves the alignments for two reasons: it limits overfitting by reducing the size of the minimization space and allows to translate the idea of keeping distances and angles, resulting from the similarity in the space structure. The resulting problem is known as Orthogonal Procrustes. It also admits a closed-form solution through a singular value decomposition (cubic complexity). Thus, if their correspondences are known, the translation matrix between two sets of points can be inferred without too many difficulties. The next step leading to unsupervised learning is to discover these point correspondences using Wasserstein distance.\nWasserstein Distance In a similar fashion, finding the correct mapping between two sets of word can be done by solving the following minimization problem:\n$\\mathcal{P}_{n}$ containing all the permutation matrices, the solution of the minimization, $P_t$ will be an alignment matrix giving away the pair of words. This 1 to 1 mapping can be achieved thanks to the Hungarian algorithm. It is equivalent to solve the following linear program:\nThe combination of the Procustes- Wasserstein minimization problem is the following:\nTo solve this problem, the approach of [5] was to use a stochastic optimization algorithm. As solving separately those 2 problems led to bad local optima, their choice was to select a smaller batch of size b, and perform their minimization algorithm on these sub-samples. The batch is playing the role of anchors points. Combining this with a convex relaxation for an optimal initialization, it leads to the following algorithm:\nOther unsupervised approaches Other approaches exist, but they are currently less efficient than the one described above for various reasons: complexity, efficiency\u0026hellip; We will briefly describe the two main ones below.\nOptimal transport:\nOptimal transport [6] formalizes the problem of finding a minimum cost mapping between two word embedding sets, viewed as discrete distributions. More precisely, they assume the following distributions:\nand look for a transportation map realizing:\nwhere the cost $c(\\mathbf{x}, T(\\mathbf{x}))$ is typically just $| T(\\mathbf{x}) - \\mathbf{x} |$ and $T_{\\sharp} \\mu = \\nu$ implies that the source points must exactly map to the targets.\n  Push forward operator    Yet, this transportation not always exist and a relaxation is used. Thus, the discrete optimal transport (DOT) problem consists of finding a plan $\\Gamma$ that solves where $\\mathbf{C} \\in \\mathbb{R}^{n \\times m}$, e.g., $C_{i j}=\\left|\\mathbf{x}^{(i)}-\\mathbf{y}^{(j)}\\right|$ is the cost matrix and the total cost induced by $\\Gamma$ is:\nwhere $\\Gamma$ belongs to the polytope:\nA regularization is usually added, mostly through the form of an entropy penalization:\nSome works [7] are based on these observations and then propose algorithms, effective in our case, because they adapt to the particularities of word embeddings. However, we notice that even if the efficiency is higher, the complexity is redibitive and does not allow large vocabularies. Moreover, the research is more oriented towards improving the algorithm described above with optimal transport tools rather than towards a different path. This is why we will not focus in particular on this track. We should, however, note the use of Gromov-Wasserstein distance [8], which allows calculating the distance between languages innovatively, although they are in distinct spaces, enabling to compare the metric spaces directly instead of samples across the spaces.\nAdversarial Training: Another popular alternative approach derived from the literature on generative adversarial network [9] is to align point clouds without cross-lingual supervision by training a discriminator and a generator [10]. The discriminator aims at maximizing its ability to identify the origin of an embedding. The generator of W aims at preventing the discriminator from doing so by making WX and Y as similar as possible.\nThey note $\\theta_{D}$ the discriminator parameters and consider the probability $P_{\\theta_{D}}(\\text { source }=1 | z)$ that a vector $z$ is the mapping of a source embedding (as opposed to a target embedding) according to the discriminator. The discriminator loss can then be written as:\nOn the other hand, the loss of the generator is:\nFor every input sample, the discriminator and the mapping matrix $W$ are trained successively with stochastic gradient updates to minimize $\\mathcal{L}_W$ and $\\mathcal{L}_D$.\nYet, papers [10] on the subject show that, although innovative, this framework is more useful as a pre-training for the classical model than as a full-fledged algorithm.\nMultilingual alignment A natural way to improve the efficiency of these algorithms is to consider more than 2 languages. Thus, when it comes to aligning multiple languages together, two principle approaches quickly come to mind and correspond to two optimization problems:\n Align all languages to one pivot language, often English, without considering the loss function other alignments. This leads to low complexity but also to low efficiency between the very distinct language, forced to transit through English. Align all language pairs by putting them all in the loss function, without giving importance to any one in particular. If this improves the efficiency of the algorithm, the counterpart is in the complexity, which is very important because it is quadratic in the number of languages.    Example of both approaches to align multiple languages.    A trade-off must therefore be found between these two approaches.\nLet us consider $\\mathbf{X}_i$ word embeddings for each language $i$, $i=0$ can be considered as the reference language, $\\mathbf{W}_i$ is the mapping matrix we want to learn and $\\mathbf{P}_i$ the permutation matrix. The alignment of multiple languages using a reference language as pivot can be resumed by the following problem:\nAs said above, although this method gives satisfying results concerning the translations towards the reference language, it provides poor alignment for the secondary languages between themselves.\nTherefore an interesting way of jointly aligning multiple languages to a common space has been brought through by Alaux et al. [11].\nThe idea is to consider each interaction between two given languages, therefore the previous sum becomes a double sum with two indexes i and j. To prevent the complexity from being to high and to keep track and control over the different translations, each translation between two languages is given a weight $\\alpha_{i j}$:\nThe choice of these weights depends on the importance we want to give to the translation from language i to language j.\nThe previous knowledge we have on the similarities between two languages can come at hand here, for they will have a direct influence on the choice of the weight. However, choosing the appropriate weights can be uneasy. For instance, giving a high weight to a pair of close languages can be unnecessary, and doing the same for two distant languages can be a waste of computation. To effectively reach this minimization, they use an algorithm very similar to the stochastic optimization algorithm described above.\nAt the beginning, we wanted to use this algorithm to incorporate exogenous knowledge about languages to propose constants $\\alpha_{i j}$ more relevant and leading to greater efficiency. Different techniques could result in these parameters: from the mathematical literature such as the Gromov-Wasserstein distance evoked above or from the linguistic literature, using the etymological tree of languages to approximate their degree of proximity or even from both. In the article implementing this algorithm, it is specified that the final $\\alpha_{i j}$ is actually very simple: N if we consider a link to the pivot or 1 otherwise. Practical simulations have also led us to doubt the efficiency of this idea. This is why we decided to focus on the idea below that seemed more promising rather than on multialignments.\nWord translation as a retrieval task: Post-alignment Lexicon Induction The core idea of the least-square problem of optimization in Wasserstein Procrustes is to minimize the distance between a word and its translation. Hence, given the alignment, the inference part first consisted of finding the nearest neighbors (NN). Yet, this criterion had a major issue: Nearest neighbors are by nature asymmetric: y being a K-NN of x does not imply that x is a K-NN of y. In high-dimensional spaces, this leads to a phenomenon that is detrimental to matching pairs based on a nearest neighbor rule: some vectors, called hubs, are with high probability nearest neighbors of many other points, while others (anti-hubs) are not nearest neighbors of any point. [12]\nTwo solutions to this problem have been brought through new criteria, aiming to give similarity measure between two embeddings, thus matching them appropriately. Among them, the most popular is Cross-Domain Similarity Local Scaling (CSLS) [10]. Others exist, such as Inverted Softmax (ISF)[13]. Yet, they usually require to estimate noisy parameter in an unsupervised setting where we do not have a direct cross-validation criterion.\nThe idea behind CSLS is quite simple: it is a matter of calculating a cosine similarity between the two vectors, subtracting a penalty if one or both of the vectors is also similar at many other points.\nMore formally, we denote by $\\mathcal{N}_{\\mathrm{T}} (\\mathbf{W} x_s)$ the neighboors of $\\boldsymbol{x}_S$ for the target language, after the alignment (hence the presence of $\\mathbf{W}$).\nSimilarly we denote by $\\mathcal{N}_{\\mathrm{S}}(y_t)$ the neighborhood associated with a word $t$ of the target language. The penalty term we consider is the mean similarity of a source embedding $x_s$ to its target neighborhood:\nwhere cos(\u0026hellip;) is the cosine similarity.\nLikewise we denote by $r_{\\mathrm{S}}\\left(y_{t}\\right)$ the mean similarity of a target word $y_{t}$ to its neighborhood. Finally, the CSLS is defined as:\nHowever, it may seem irrelevant to align the embedding words with the NN criterion metric and to use the CSLS criterion in the inference phase. Indeed, it creates a discrepancy between the learning of the translation model and the inference: the global minimum on the set of vectors of one does not necessarily correspond to one of the other. This naturally led to modify the least-square optimization problem to propose a loss function associated with CSLS.\nBy assuming that word vectors are $\\ell_{2}-$ normalized, we have:\nSimilarly, we have:\nTherefore, finding the $k$ nearest neighbors of $\\mathbf{W} \\mathbf{x}_i$ among the elements of $\\mathbf{Y}$ is equivalent to finding the $k$ elements of $\\mathbf{Y}$ which have the largest dot product with $\\mathbf{W} \\mathbf{x}_i$. This equivalent formulation is adopted because it leads to a convex formulation when relaxing the orthogonality constraint on $\\mathbf{W}$. This optimization problem with the Relaxed CSLS loss (RCSLS) is written as:\nA convex relaxation can then be computed by considering the convex hull of $\\mathcal{O}_d$, i.e., the unit ball of the spectral norm. The results of the papers [10] point out that RCSLS outperforms state of the art by, on average, 3 to 4% in accuracy compared to benchmark. This shows the importance of using the same criterion during training and inference.\nSuch an improvement using a relatively simple deterministic function led us to wonder whether we could go even further in improving performance. More precisely, considering Word translation as a retrieval task, the framework implemented was that of a ranking problem. To find the right translation, it was essential to optimally rank potential candidates. This naturally led us to want to clearly define this ranking problem and use the state of the art research on raking to tackle it. In this framework, the use of simple deterministic criteria such as NN, CSLS, or ISF was a low-tech answer and left a large field of potential improvement to be explored.\nHowever, we wanted to keep the unsupervised framework, hence the idea of training the learning to rank algorithms on the learning of the translation of a language pair, English-Spanish, for instance, assuming the existence of a dictionary. This would then allow us to apply the learning to rank algorithm for another language pair without a dictionary, English-Italian, for instance. Similarly to the case of CSLS, the criterion can be tested first at the end of the alignment carried out thanks to the Procrustes-Wasserstein method. Then, in a second step, it can be integrated directly through the loss function in the alignment step. The following will quickly present the learning to rank framework to understand our implementation in more detail.\nLearning to Rank A ranking problem is defined as the task of ordering a set of items to maximize the utility of the entire set. Such a question is widely studied in several domains, such as Information Retrieval or Natural Language Processing. For example, on any e-commerce website, when given a query \u0026ldquo;iPhone black case\u0026rdquo; and the list of available products, the return list should be ordered by the probability of getting purchased. One can start understanding why a ranking problem is different than a classification or a regression task. While their goal is to predict a class or a value, the ranking task needs to order an entire list, such that the higher you are, the more relevant you should be.\nTheoretical framework Let\u0026rsquo;s start by diving into the theoretical framework of Learning to Rank. Let $\\psi := { (X,Y) \\in \\mathcal{X}^n \\times \\mathbb{R}^{n}_{+}}$ be a training set, where:\n $X \\in \\mathcal{X}^n$ is a vector, also defined as $(x_1,\u0026hellip;,x_n)$ where $x_i$ is an item. $Y \\in \\mathbb{R}^{n}_{+}$ is a vector, also defined as $(y_1,\u0026hellip;,y_n)$ where $y_i$ is a relevance labels. $\\mathcal{X}$ is the space of all items.  Furthermore, we define an item $x \\in \\mathcal{X}$ as a query-documents pair $(q,d)$.\nThe goal is to find a scoring function $f : \\mathcal{X}^n \\rightarrow \\mathbb{R}^{n}_{+}$ that would minimizes the following loss :\nwhere $l : (\\mathbb{R}^{n}_{+})^2 \\rightarrow \\mathbb{R}$ is a local loss function.\nOne first et very important note is how $f$ is defined. This could be done in two ways:\n We consider $f$ as a univariate scoring function, meaning that it can be decomposed into a per-item scoring function with $u : x \\mapsto \\mathbb{R}_+$. We will have $f(X) = [u(x_0), \\cdots , u(x_n)]$. We consider $f$ as a multivariate scoring function, meaning that each item is scored relatively to every other item in the set, with $f$ in $\\mathbb{R}^{n}_{+}$. This means that changing one item could change the score of the rest of the set.  While the first option is simpler to implement, the second one is much closer to reality, as an item\u0026rsquo;s relevance often depends on the distribution its in. For example, an article\u0026rsquo;s relevance to an e-commerce query will always depend on what the website offers you next to it.\nWe now have to define some metrics in order to judge how good a ranking is. We start by defining the Discounted Cumulativ Gain (DCG) of a list:\nwhere:\n $Y = (y_1,\u0026hellip;,y_n)$ are the ground truth labels $\\pi(j)$ is the rank of the j-th item in X $\\frac{1}{ln_{2}(1+\\pi(j))}$ is the discount factor $k$ is how much we want to go deep into the list. A low value of $k$ means that we want to focus on how well ranked the start of our list is.  Most of the time however we want to compare this metric to the DCG obtained from the ground truth labels. We then define:\nwhere $\\pi^*$ is the item permutations induced by Y.\nLoss functions In\nwe defined $l$ as a loss function between two ordered sets of items. One approach could be to use the metrics defined above, but as they are non-differentiable, this is not a feasible choice. Therefore, we have to develop some sort of surrogate loss function, differentiable, and with the same goal as our metric. Before diving into the possible approaches, one must define what pointwise, pairwise, and listwise loss functions are.\nA pointwise loss will only compare one predicted label to the real one. Therefore, each item\u0026rsquo;s label is not compared to any other piece of information. A pairwise loss will compare 2 scores from 2 items at the same time. With the pairwise loss, a model will minimize the number of pairs in the wrong order relative to the proper labels. A listwise loss can capture differences in scores throughout the entire list of items. While this is a more complex approach, it allows us to compare each score against the others.\nLet\u0026rsquo;s give an example for each sort of loss function, starting with a pointwise one. The sigmoid cross entropy for binary relevance labels can be defined as:\nwhere $p_j = \\frac{1}{1 + e^{-\\hat y_j}}$ and $\\hat Y$ is the predicted labels for each item from one model.\nThe pairwise logistic loss [1] is a pairwise loss function that compares if pair of items are ordered in the right order. We can define it as:\nwhere $\\mathbb{I}_{x}$ is the indicator function.\nFinally, a listwise loss function like the Softmax cross-entropy [2] can be defined as:\nAll of these loss functions are surrogates that try to capture the goal of our metrics. Another approach would be to define a listwise loss function, as close as our metrics as possible. For example, one could try to build a differentiable version of the NDCG [3]\nApproxNDCG: a differentiable NDCG Let\u0026rsquo;s take a query $q$, and define several useful functions:\nthe relevance of an item $x$ regarding of the fixed query $q$, and\nthe position of $x$ in the ranked list $\\pi$ and finally, $\\mathbb{I}_{{\\pi(x) \\leq k}}$ still represents the indicator function of the set ${\\pi(x) \\leq k}$. The idea is to use an differentiable approximation of the indicator function. One can show that we have the following approximation:\nwhere $\\alpha$ is a hyperparameter.\n  Example of approximation of the Indicator function for various values of alpha.    For a fixed query, we can re-define the DCG metric with the following equality :\nWe now have to get an approximation of the $\\pi$ function. The idea here is to get back to an indicator function since it is possible to compute them. We will be using the following equality :\nwhere $s_x$ is defined as the score given to $x$ according to $f$, and define an approximation of $\\pi$ with:\nWe can now define our differentiable version of the DCG metric by using these approximations.\nRUBI: Ranked Unsupervised Bilingual Induction Motivations: Let\u0026rsquo;s describe more precisely the functioning of our algorithm. Two points guided our approach:\n From a linguistic point of view, there is obviously a learning to learn phenomenon for languages. We observe that by assimilating the structure of the new language, its grammar, and vocabulary to one of the already known languages, it is easier for us to create links that help learning. It is the search for these links that motivate us. We are convinced that they can be useful when inferring vocabulary. Improvement induced by using the CSLS criterion suggests that there are complex geometrical phenomena (going beyond the existence as mentioned above of hubs) within the representations of languages, both ante, and post-alignment. Understanding these phenomena can lead to significantly increased efficiency.  Framework: Our goal is the same as for unsupervised bilingual alignment: we have a source language A and a target language B with no parallel data between the two. We want to derive an A-B dictionary, a classic BLI task. Our study\u0026rsquo;s specificity is to assume that we also have a C language and an A-C dictionary at our disposal. To set up the learning to learn procedure, we proceed in 2 steps:\n Learning: Using the Procrustes-Wasserstein algorithm, we align languages A and C in an unsupervised way. We then build a corpus of queries between the words from language A known from our dictionary and their potential translation into language C. Classical methods proposed the translation that maximized the NN or CSLS criteria. We use deep learning as part of our learning to rank framework to find a more complex criterion. One of the innovative features of our work is, therefore, to allow access to a much larger class of functions for the vocabulary induction stage. A sub-part of the dictionary is used for cross-validation. The way of rating the relevance of the potential translations, the inputs of the algorithm, the loss functions are all parameters that we studied and that are described in the next section. Prediction: We thus have at the end of the training an algorithm taking as input a vocabulary word, in the form of an embedding and a list of potential translations. Our algorithm\u0026rsquo;s output is the list sorted according to the learned criteria of these possible translations, the first word corresponding to the most probable translation, and so on. We first perform the alignment of languages A and B using the Procrustes-Wasserstein algorithm again. In a second step, thanks to the learning to rank, we perform the lexicon induction step.  Finally, a final conceptual point is important to raise. In the context of the CSLS criterion, we have seen in the above that its use after alignment has improved. However, actually incorporating it in the alignment phase by modifying the loss function has allowed for greater consistency and a second improvement. However, these two changes were separated. Yet, the learning to rank framework is quite different. The main reason is the non-linearity resulting from deep-learning, unlike CSLS. Therefore, the global optimization is much more complex and does not allow relaxation to get back to a convex case. However, it is an area for improvement to be considered very seriously for future work.\nResults We can split our results into two very distinct parts. They both depend on how the Learning to Rank item sets are built. Given a word, you can build the list of potential traduction from a CSLS criterion and then force or not the right translation presence. This choice needs to be discussed thoroughly. First, let\u0026rsquo;s quickly present some results with and without the correct prediction forced in the query.\nWith the forced prediction    Method EN-ES ES-EN EN-FR FR-EN     Wass. Proc. - NN 77.2 75.6 75.0 72.1   Wass. Proc. - CSLS 79.8 81.8 79.8 78.0   Wass. Proc. - ISF 80.2 80.3 79.6 77.2   Adv. - NN 69.8 71.3 70.4 61.9   Adv. -CSLS 75.7 79.7 77.8 71.2   RCSLS+spectral 83.5 85.7 82.3 84.1   RCSLS 84.1 86.3 83.3 84.1   RUBI 93.3 (DE) 91.6 (FR) 93.8 (NL) 91.9 (IT)    EN-DE DE-EN EN-RU RU-EN   Wass. Proc. - NN 66.0 62.9 32.6 48.6   Wass. Proc. - CSLS 69.4 66.4 37.5 50.3   Wass. Proc. - ISF 66.9 64.2 36.9 50.3   Adv. - NN 63.1 59.6 29.1 41.5   Adv. -CSLS 70.1 66.4 37.2 48.1   RCSLS+spectral 78.2 75.8 56.1 66.5   RCSLS 79.1 76.3 57.9 67.2   RUBI 93.6 (HU) 89.8 (FR) 83.7 (HU) -    1: Loss function impact - Loss used for the Learning to Rank model. In other experiments, we found that ApproxNDCG and List MLE continue to perform similarly, hence our default choice of Approx NDCG.\n2: Group size impact - The group size measures how many items the Learning to Rank model takes as input simultaneously (multivariate vs. univariate). However, the dilemma is to optimize the computation time because increasing the group size exponentially increases the number of calculations.\n3: CSLS feature impact - The features for each potential translation in a query can incorporate several elements:\n the word embedding of the potential translation (size 300) the word embedding of the query (size 300) pre-computed features such as distance to query word in the aligned vector space, CSLS distance, ISF\u0026hellip;  Those features are crucial for learning as it will entirely rely on it. At first, we decided to only use the word embedding of the potential translation and the query. That gave us a 600 feature list. However, after several experiments, we noticed that the learning to rank algorithm, despite the variation of the parameters, could not learn relevant information from these 600 features, the performance was poor. The function learned through deep learning was less efficient than a simple Euclidean distance between the potential translation and the query (NN criterion). In fact, after consulting the literature, we realized that using such a number of features is not very common. Most algorithms were only using pre-computed features (often less than a hundred). Although this information is already interesting in itself, we, therefore, turned to the second approach. We chose to restrict ourselves to certain well-specified types of pre-computed features to evaluate their full impact. More precisely, for a fixed k parameter, we provided as features the euclidean distance to the query and the CSLS(i) \u0026ldquo;distance\u0026rdquo; for i ranging from 1 to k. In other words, we provided information about the neighborhood through the penalties described in the section on CSLS. Training with the full embeddings was also performed but did not lead to any improvements.\n4: Query size impact - Number of potential translations given with a query (number of items). There is a low incidence of the number of queries on the results, a very slight but perceptible decrease. Therefore, the algorithm is able, despite a large number of candidates, to discern the correct information.\nPlot of the BLI criterion in the training step according to the CSLS criterion, i.e., the quality of the language\u0026rsquo;s alignment for learning with English. The trend that emerges is that of a very clear positive correlation (linear trend plotted in red, (R ^2 = 0.82)). We have also shown the averages per language family (Romance, Germanic and Uralic). In conclusion, it seems easier to learn using a language that is well-aligned with English. Although this seems logical, it is not that obvious. Three clusters seem to appear in conjunction with the different families. Romance languages are associated with a high rate of alignment with English and, therefore, with high performance in the learning stage. The Germanic language cluster has a lower performance combined with a slightly lower quality alignment. Knowing that English belongs to the Germanic language type, it is interesting to note this slight underperformance in alignment compared to Romance. Finally, the Slave cluster shows the worst performance in terms of alignment with English and, therefore, also the worst for the learning step.\nWithout forced prediction   Ablation study for the same pipeline as above, but without the right prediction forced into the query.    Without going into too many details, the same trends as above appear here and hold even when the proper translation is not artificially added to the query.\nThe main difference comes from the value of the BLI results: we only achieve the same results as the state of the art, or slightly better. We discuss in the conclusion the implication of these results, and especially the importance of forcing the right translation to appear in each query.\nConclusion If in the Learning to rank framework, a query without at least one relevant item doesn\u0026rsquo;t have a lot of sense, this is not something one can ensure when working with unsupervised translation. If it is clear that given a query where the correct translation appears, a Learning to Rank model surpasses existing methods, it is still unclear on how to achieve such a query every time. While one way could be to extend the query size drastically, one still has to keep in mind the memory capability of such a model. Another bias might come from every query where the correct translation does not appear naturally (thus always giving poor results to every model except \u0026ldquo;forced translation\u0026rdquo; model).\nWe believe that leveraging the knowledge of previous idioms acquisition can keep leading to many improvements over existing models. This could be achieved thanks to Learning to Rank.\nReferences 1: CHEN, WEI, YAN LIU, TIE, LAN, YANYAN, MING MA, ZHI \u0026amp; LI, HANG 2009 Ranking measures and loss functions in learning to rank. In Advances in Neural Information Processing Systems 22 (ed. Y. Bengio, D. Schuurmans, J. D. Lafferty, C. K. I. Williams \u0026amp; A. Culotta), pp. 315–323. Curran Associates, Inc\n2: CAO, ZHE, QIN, TAO, LIU, TIE-YAN, TSAI, MING-FENG \u0026amp; LI, HANG 2007 Learn- ing to rank: From pairwise approach to listwise approach. In Proceedings of the 24th International Conference on Machine Learning, pp. 129–136. New York, NY, USA: ACM.\n3: QIN et al. A general approximation framework for direct optimization of information retrieval measures.\n4: Ilya Sutskever, Thomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean 2013. Distributed Representations of Words and Phrases and their Compositionality\n5: Quentin Berthet, Edouard Grave and Armand Joulin: Unsupervised Alignment of Embeddings with Wasserstein Procrustes, 2018\n6: Cédric Villani. Topics in optimal transportation. Number 58. American Mathematical Soc., 2003.\n7: David Alvarez-Melis and Tommi Jaakkola. Gromov-wasserstein alignment of word embedding spaces. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018.\n8: Mikhail Gromov. Metric structures for Riemannian and non-Riemannian spaces. Springer Science \u0026amp; Business Media, 2007.\n9: Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, pp. 2672–2680, 2014.\n10: Conneau, A., Lample, G., Ranzato, M., Denoyer, L., and Jégou, H: Word translation without parallel data, 2017\n11: Jean Alaux, Edouard Grave, Marco Cuturi and Armand Joulin: Unsupervised hyperaligment for multilingual word embeddings, 2019\n12: Georgiana Dinu, Angeliki Lazaridou, and Marco Baroni. Improving zero-shot learning by mitigating the hubness problem. International Conference on Learning Representations, Workshop Track, 2015.\n13: Smith, S. L., Turban, D. H., Hamblin, S., and Hammerla, N. Y.: Bilingual word vectors, orthogonal transformations and the inverted softmax., 2017\n","date":1598832000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598832000,"objectID":"e67abdd19642fc4903fa20c582535df6","permalink":"https://gguinet.github.io/post/semi-supervised/","publishdate":"2020-08-31T00:00:00Z","relpermalink":"/post/semi-supervised/","section":"post","summary":"This blog post contains an introduction to Unsupervised Bilingual Alignment and Multilingual Alignment. We also go through the theoretical framework behind Learning to Rank and discuss how it might help produce better alignments in a Semi-Supervised fashion. We both hope that this post will serve as a good introduction to anyone interested in those topics.","tags":null,"title":"From Learning to Rank to Unsupervised Translation: towards a deep learning archaeologist ?","type":"post"},{"authors":null,"categories":null,"content":"We consider the problem of aligning two sets of continuous word representations, corresponding to languages, to a common space in order to infer a bilingual lexicon. It was recently shown that it is possible to infer such lexicon, without using any parallel data, by aligning word embeddings trained on monolingual data. Such line of work is called unsupervised bilingual induction. By wondering whether it was possible to gain experience in the progressive learning of several languages, we asked ourselves to what extent we could integrate the knowledge of a given set of languages when learning a new one, without having parallel data for the latter. In other words, while keeping the core problem of unsupervised learning in the latest step, we allowed the access to other corpora of idioms, hence the name semi-supervised. This led us to propose a novel formulation, considering the lexicon induction as a ranking problem for which we used recent tools of this machine learning field. Our experiments on standard benchmarks, inferring dictionary from English to more than 20 languages, show that our approach consistently outperforms existing state of the art benchmark. In addition, we deduce from this new scenario several relevant conclusions allowing a better understanding of the alignment phenomenon.\n","date":1598832000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598832000,"objectID":"52abb85250a6f9663264b9d01aa97ae3","permalink":"https://gguinet.github.io/project/semi-supervised/","publishdate":"2020-08-31T00:00:00Z","relpermalink":"/project/semi-supervised/","section":"project","summary":"We consider the problem of aligning two sets of continuous word representations, corresponding to languages, to a common space in order to infer a bilingual lexicon. It was recently shown that it is possible to infer such lexicon, without using any parallel data, by aligning word embeddings trained on monolingual data. Such line of work is called unsupervised bilingual induction. By wondering whether it was possible to gain experience in the progressive learning of several languages, we asked ourselves to what extent we could integrate the knowledge of a given set of languages when learning a new one, without having parallel data for the latter. In other words, while keeping the core problem of unsupervised learning in the latest step, we allowed the access to other corpora of idioms, hence the name semi-supervised. This led us to propose a novel formulation, considering the lexicon induction as a ranking problem for which we used recent tools of this machine learning field. Our experiments on standard benchmarks, inferring dictionary from English to more than 20 languages, show that our approach consistently outperforms existing state of the art benchmark. In addition, we deduce from this new scenario several relevant conclusions allowing a better understanding of the alignment phenomenon.","tags":null,"title":"Semi-Supervised Learning for Bilingual Lexicon Induction","type":"project"},{"authors":null,"categories":null,"content":"The aim of this paper is to study the causal effect of the use of tranexamic acid in head trauma patients, using a dataset provided by the AP-HP (Paris Hospital), gathering medical information on major trauma victims. In observational studies, one of the major difficulties is to cope with the lack of an adequate control group. This is because, unlike in randomized experiments, there is a bias in the administration of treatment.\nIn (1), we present the associated statistical framework. In (2), we describe three of the main techniques used for matching: coarse exact matching, cardinality matching and propensity matching. Since there is little statistical evidence for the effectiveness of these techniques, we designed and implemented experiments to provide empirical results. We generated several synthetic datasets with various underlying complexities and compared our methods on these datasets. In (3), we outline the methodology and results of this experiment. Thereafter, we applied our methods on the trauma database after preprocessing it. This allowed us to obtain an estimate of the treatment effect, which we present in (4). Finally, because the use of the trauma database involves imputation of missing data, we study the robustness to missing data of our three matching methods in (5).\n","date":1567209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567209600,"objectID":"af78d2804a77745d9bec9fffef72e930","permalink":"https://gguinet.github.io/project/causalinf/","publishdate":"2019-08-31T00:00:00Z","relpermalink":"/project/causalinf/","section":"project","summary":"The aim of this paper is to study the causal effect of the use of tranexamic acid in head trauma patients, using a dataset provided by the AP-HP (Paris Hospital), gathering medical information on major trauma victims. In observational studies, one of the major difficulties is to cope with the lack of an adequate control group. This is because, unlike in randomized experiments, there is a bias in the administration of treatment. In (1), we present the associated statistical framework. In (2), we describe three of the main techniques used for matching: coarse exact matching, cardinality matching and propensity matching. Since there is little statistical evidence for the effectiveness of these techniques, we designed and implemented experiments to provide empirical results. We generated several synthetic datasets with various underlying complexities and compared our methods on these datasets. In (3), we outline the methodology and results of this experiment. Thereafter, we applied our methods on the trauma database after preprocessing it. This allowed us to obtain an estimate of the treatment effect, which we present in (4). Finally, because the use of the trauma database involves imputation of missing data, we study the robustness to missing data of our three matching methods in (5).","tags":null,"title":"Estimating the effect of Tranexamic Acid on Head Traumatized patients with Causal Matching","type":"project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://gguinet.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"How are Autism Spectrum Disorders closely linked to the phenomenen of neurons birth and death? During a year-long project, I collaborated with Dr Guillaume Dumas and Dr Jean-Pierre Changeux, from the Pasteur Institute in Paris. The ultimate goal was to seek new conceptual and methodological approaches towards a better understanding of neuronal coordination dynamics. Combining computational neuroscience, system biology, and Reinforcement Learning, we were able to propose a more biological realist model of learning and then to implement it through a neural network. More broadly, this work also aims to examine the relationship between biological learning mechanisms and those used in artificial intelligence algorithms, an exciting and challenging topic. Below is the poster we presented at the synposium Neural networks – From brains to machines and vice versa.\n","date":1539216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539216000,"objectID":"ffa0a77c189c86ec315893589855b53a","permalink":"https://gguinet.github.io/project/synapticgnw/","publishdate":"2018-10-11T00:00:00Z","relpermalink":"/project/synapticgnw/","section":"project","summary":"How are Autism Spectrum Disorders closely linked to the phenomenen of neurons birth and death? During a year-long project, I collaborated with [Dr Guillaume Dumas](http://www.extrospection.eu) and [Dr Jean-Pierre Changeux](https://www.college-de-france.fr/site/jean-pierre-changeux/), from the Pasteur Institute in Paris. The ultimate goal was to seek new conceptual and methodological approaches towards a better understanding of neuronal coordination dynamics. Combining computational neuroscience, system biology, and Reinforcement Learning, we were able to propose a more biological realist model of learning  and then to implement it through a neural network. More broadly, this work also aims to examine the relationship between biological learning mechanisms and those used in artificial intelligence algorithms, an exciting and challenging topic. Below is the poster we presented at the synposium [Neural networks – From brains to machines and vice versa](https://research.pasteur.fr/fr/event/neural-networks-from-brains-to-machines-and-vice-versa/).","tags":null,"title":"Synaptic epigenesis of the Global Neuronal Workspace","type":"project"}]